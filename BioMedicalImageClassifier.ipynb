{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMu3q5oMfPcwXwXLU4VgVEQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshyadv/Worked-up/blob/main/BioMedicalImageClassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from medmnist import INFO, Evaluator\n",
        "from medmnist.dataset import BreastMNIST\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from PIL import Image\n",
        "import os"
      ],
      "metadata": {
        "id": "ou6GXQThaUzx"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "EJE0Ve8ya_T7"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (resizing to 224x224 and normalizing)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])  # Normalize to [-1, 1]\n",
        "])\n"
      ],
      "metadata": {
        "id": "dTXFFJUMbCLc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BreastMNIST dataset\n",
        "dataset = BreastMNIST(split='train', transform=transform, download=True)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "test_dataset = BreastMNIST(split='test', transform=transform, download=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49VZ_tC9bFTJ",
        "outputId": "09b6748c-d5b7-4bef-defd-7739750be571"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "9hSHP1m-bIe2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the ResNet-50 model\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.resnet50 = models.resnet50(pretrained=True)\n",
        "        # Modify ResNet-50 to accept 1-channel input instead of 3\n",
        "        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, 128)  # Change output to 128 for concatenation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet50(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "kAVrd5DbfACe"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model mimicking QCNN\n",
        "class QCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 128)  # Adjust based on input size\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 128 * 28 * 28)  # Flatten for fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "j9csGCshbNov"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hybrid model that combines QCNN and ResNet-50\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.qcnn = QCNN()\n",
        "        self.resnet50 = ResNet50()\n",
        "        self.fc = nn.Linear(128 + 128, 2)  # Combine 128 from QCNN and 128 from ResNet-50\n",
        "\n",
        "    def forward(self, x):\n",
        "        qcnn_output = self.qcnn(x)\n",
        "        resnet_output = self.resnet50(x)\n",
        "        combined = torch.cat((qcnn_output, resnet_output), dim=1)\n",
        "        output = self.fc(combined)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "DSNjewn5gHUY"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the hybrid model and move it to GPU if available\n",
        "model = HybridModel().to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePGKlmbebQUp",
        "outputId": "1d744318-9347-4b44-bb69-16b1b162889d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 174MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define, criterion, optimizer as before\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Edg8ZhCbTBJ",
        "outputId": "03224e30-7b6d-420b-a6a5-ec68a634cd13"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)\n"
      ],
      "metadata": {
        "id": "zSGu4meFbWXf"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    accuracy = 100. * correct / len(val_loader.dataset)\n",
        "    return val_loss, accuracy\n"
      ],
      "metadata": {
        "id": "aqi9XY_ZbbC_"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "patience = 10\n",
        "early_stop_count = 0\n",
        "\n",
        "num_epochs = 100  # Start with a higher number of epochs\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "    print(f'Epoch {epoch}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_count = 0  # Reset the counter if we get a new best model\n",
        "    else:\n",
        "        early_stop_count += 1\n",
        "        if early_stop_count >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Adjust the learning rate based on the validation loss\n",
        "    scheduler.step(val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh3hy23LbeYw",
        "outputId": "d4cf88af-3eaa-4233-cef3-6ac92995aff3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Training Loss: 0.3507, Validation Loss: 7.6420, Validation Accuracy: 74.55%\n",
            "Epoch 2/100, Training Loss: 0.2664, Validation Loss: 2.5924, Validation Accuracy: 79.09%\n",
            "Epoch 3/100, Training Loss: 0.2229, Validation Loss: 1.1052, Validation Accuracy: 77.27%\n",
            "Epoch 4/100, Training Loss: 0.1210, Validation Loss: 1.9032, Validation Accuracy: 77.27%\n",
            "Epoch 5/100, Training Loss: 0.1436, Validation Loss: 1.3685, Validation Accuracy: 80.91%\n",
            "Epoch 6/100, Training Loss: 0.1568, Validation Loss: 2.1315, Validation Accuracy: 72.73%\n",
            "Epoch 7/100, Training Loss: 0.1171, Validation Loss: 1.2961, Validation Accuracy: 70.91%\n",
            "Epoch 8/100, Training Loss: 0.0838, Validation Loss: 1.4885, Validation Accuracy: 79.09%\n",
            "Epoch 9/100, Training Loss: 0.0794, Validation Loss: 1.4459, Validation Accuracy: 80.00%\n",
            "Epoch 10/100, Training Loss: 0.0732, Validation Loss: 1.2704, Validation Accuracy: 77.27%\n",
            "Epoch 11/100, Training Loss: 0.0201, Validation Loss: 1.2782, Validation Accuracy: 79.09%\n",
            "Epoch 12/100, Training Loss: 0.0145, Validation Loss: 1.2511, Validation Accuracy: 79.09%\n",
            "Epoch 13/100, Training Loss: 0.0094, Validation Loss: 1.2712, Validation Accuracy: 79.09%\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model and calculate metrics\n",
        "def test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "    return all_preds, all_labels\n"
      ],
      "metadata": {
        "id": "tRIZV7sVcN7P"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test and get predictions\n",
        "preds, labels = test(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMEzILw2cPiJ",
        "outputId": "0698d58b-fd68-49d0-a70c-aa70ed455593"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.85%\n",
            "Precision: 0.88\n",
            "Recall: 0.92\n",
            "F1 Score: 0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output images with predictions\n",
        "output_dir = 'output_images'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for i, (pred, label) in enumerate(zip(preds, labels)):\n",
        "    img, _ = test_dataset[i]\n",
        "    img = transforms.ToPILImage()(img)\n",
        "    # Include prediction and label in the filename\n",
        "    img.save(os.path.join(output_dir, f'img_{i}_pred_{pred}_label_{label}.png'))\n",
        "\n",
        "print(f\"Images saved to '{output_dir}' directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMUAORyOgyP2",
        "outputId": "1502251e-daa9-4145-de50-2fabb3130aac"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved to 'output_images' directory.\n"
          ]
        }
      ]
    }
  ]
}