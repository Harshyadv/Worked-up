{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN9P00rk3rwx7smYM89zZAj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Harshyadv/Worked-up/blob/main/CNNWithRESNET(50)Integration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from medmnist import INFO, Evaluator\n",
        "from medmnist.dataset import BreastMNIST\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision.models import resnet50, ResNet50_Weights"
      ],
      "metadata": {
        "id": "ou6GXQThaUzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "EJE0Ve8ya_T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations (resizing to 224x224 and normalizing)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[.5], std=[.5])  # Normalize to [-1, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "dTXFFJUMbCLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the BreastMNIST dataset\n",
        "dataset = BreastMNIST(split='train', transform=transform, download=True)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "test_dataset = BreastMNIST(split='test', transform=transform, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49VZ_tC9bFTJ",
        "outputId": "b8b00366-5747-4b26-f1c2-618c400e9db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/breastmnist.npz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "9hSHP1m-bIe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet-50 model\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.resnet50 = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "        # Modify ResNet-50 to accept 1-channel input instead of 3\n",
        "        self.resnet50.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, 128)  # Change output to 128 for concatenation\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet50(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "kAVrd5DbfACe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model mimicking QCNN\n",
        "class QCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 128)  # Adjust based on input size\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 128 * 28 * 28)  # Flatten for fully connected layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "j9csGCshbNov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hybrid model that combines QCNN and ResNet-50\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.qcnn = QCNN()\n",
        "        self.resnet50 = ResNet50()\n",
        "        self.fc = nn.Linear(128 + 128, 2)  # Combine 128 from QCNN and 128 from ResNet-50\n",
        "\n",
        "    def forward(self, x):\n",
        "        qcnn_output = self.qcnn(x)\n",
        "        resnet_output = self.resnet50(x)\n",
        "        combined = torch.cat((qcnn_output, resnet_output), dim=1)\n",
        "        output = self.fc(combined)\n",
        "        return output"
      ],
      "metadata": {
        "id": "DSNjewn5gHUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the hybrid model and move it to GPU if available\n",
        "model = HybridModel().to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePGKlmbebQUp",
        "outputId": "31570ffb-52f8-4b20-d371-7f0e9462ea01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define, criterion, optimizer as before\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)"
      ],
      "metadata": {
        "id": "4Edg8ZhCbTBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)"
      ],
      "metadata": {
        "id": "zSGu4meFbWXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation loop\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    val_loss /= len(val_loader)\n",
        "    accuracy = 100. * correct / len(val_loader.dataset)\n",
        "    return val_loss, accuracy"
      ],
      "metadata": {
        "id": "aqi9XY_ZbbC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Early stopping variables\n",
        "best_val_loss = float('inf')\n",
        "patience = 10\n",
        "early_stop_count = 0\n",
        "\n",
        "num_epochs = 100  # Start with a higher number of epochs\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_accuracy = validate(model, val_loader, criterion, device)\n",
        "    print(f'Epoch {epoch}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "    # Check for early stopping\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_count = 0  # Reset the counter if we get a new best model\n",
        "    else:\n",
        "        early_stop_count += 1\n",
        "        if early_stop_count >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    # Adjust the learning rate based on the validation loss\n",
        "    scheduler.step(val_loss)\n",
        "    print(f'Learning rate: {scheduler.get_last_lr()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh3hy23LbeYw",
        "outputId": "9893f05c-1e36-450b-8a31-ac0896ffce1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Training Loss: 0.5784, Validation Loss: 0.5882, Validation Accuracy: 70.00%\n",
            "Learning rate: [0.001]\n",
            "Epoch 2/100, Training Loss: 0.4411, Validation Loss: 0.6459, Validation Accuracy: 58.18%\n",
            "Learning rate: [0.001]\n",
            "Epoch 3/100, Training Loss: 0.3185, Validation Loss: 0.6171, Validation Accuracy: 61.82%\n",
            "Learning rate: [0.001]\n",
            "Epoch 4/100, Training Loss: 0.2969, Validation Loss: 0.5568, Validation Accuracy: 70.00%\n",
            "Learning rate: [0.001]\n",
            "Epoch 5/100, Training Loss: 0.2388, Validation Loss: 1.0764, Validation Accuracy: 77.27%\n",
            "Learning rate: [0.001]\n",
            "Epoch 6/100, Training Loss: 0.1764, Validation Loss: 0.9605, Validation Accuracy: 73.64%\n",
            "Learning rate: [0.001]\n",
            "Epoch 7/100, Training Loss: 0.2023, Validation Loss: 0.7292, Validation Accuracy: 70.00%\n",
            "Learning rate: [0.001]\n",
            "Epoch 8/100, Training Loss: 0.1791, Validation Loss: 2.2042, Validation Accuracy: 70.00%\n",
            "Learning rate: [0.001]\n",
            "Epoch 9/100, Training Loss: 0.0725, Validation Loss: 0.6652, Validation Accuracy: 78.18%\n",
            "Learning rate: [0.001]\n",
            "Epoch 10/100, Training Loss: 0.1193, Validation Loss: 0.8530, Validation Accuracy: 78.18%\n",
            "Learning rate: [0.0001]\n",
            "Epoch 11/100, Training Loss: 0.0617, Validation Loss: 0.6827, Validation Accuracy: 81.82%\n",
            "Learning rate: [0.0001]\n",
            "Epoch 12/100, Training Loss: 0.0309, Validation Loss: 0.6303, Validation Accuracy: 82.73%\n",
            "Learning rate: [0.0001]\n",
            "Epoch 13/100, Training Loss: 0.0174, Validation Loss: 0.7006, Validation Accuracy: 82.73%\n",
            "Learning rate: [0.0001]\n",
            "Epoch 14/100, Training Loss: 0.0108, Validation Loss: 0.6772, Validation Accuracy: 82.73%\n",
            "Early stopping triggered.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model and calculate metrics\n",
        "def test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.squeeze().to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds)\n",
        "    recall = recall_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds)\n",
        "    print(f'Test Accuracy: {accuracy:.2f}%')\n",
        "    print(f'Precision: {precision:.2f}')\n",
        "    print(f'Recall: {recall:.2f}')\n",
        "    print(f'F1 Score: {f1:.2f}')\n",
        "\n",
        "    return all_preds, all_labels"
      ],
      "metadata": {
        "id": "tRIZV7sVcN7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the test and get predictions\n",
        "preds, labels = test(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMEzILw2cPiJ",
        "outputId": "84880b71-513d-4b0e-85a3-b08e1c143a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.84%\n",
            "Precision: 0.87\n",
            "Recall: 0.92\n",
            "F1 Score: 0.89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output images with predictions\n",
        "output_dir = 'ImageFolder'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "for i, (pred, label) in enumerate(zip(preds, labels)):\n",
        "    img, _ = test_dataset[i]\n",
        "    img = transforms.ToPILImage()(img)\n",
        "    # Include prediction and label in the filename\n",
        "    img.save(os.path.join(output_dir, f'img_{i}_pred_{pred}_label_{label}.png'))\n",
        "\n",
        "print(f\"Images saved to '{output_dir}' directory.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMUAORyOgyP2",
        "outputId": "f94b2765-a9a4-48ad-8349-f608744f27ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images saved to 'ImageFolder' directory.\n"
          ]
        }
      ]
    }
  ]
}